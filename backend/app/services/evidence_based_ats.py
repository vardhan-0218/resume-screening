import re
import logging
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime
import json
import numpy as np
from ..models.resume_models import ATSResult, ATSScoreBreakdown, ATSCandidateProfile, ATSJobProfile

logger = logging.getLogger(__name__)

class EvidenceBasedATSService:
    """
    Evidence-driven, professional Resume Screening Engine (ATS-grade).
    
    Operates strictly: never hallucinates, never invents facts, never assumes missing information.
    Uses USER'S EXACT SYSTEM PROMPT LOGIC with evidence-based extraction and deterministic scoring.
    """
    
    def __init__(self):
        """Initialize with skill synonyms, evidence tracking, and result validation"""
        self.skill_synonyms = {
            'javascript': ['js', 'javascript', 'ecmascript', 'node.js', 'nodejs'],
            'python': ['python', 'py', 'python3'],
            'machine learning': ['ml', 'machine learning', 'ai', 'artificial intelligence'],
            'react': ['react', 'reactjs', 'react.js'],
            'angular': ['angular', 'angularjs', 'angular.js'],
            'vue': ['vue', 'vuejs', 'vue.js'],
            'sql': ['sql', 'mysql', 'postgresql', 'sqlite', 'database'],
            'mongodb': ['mongodb', 'mongo', 'nosql'],
            'aws': ['aws', 'amazon web services', 'ec2', 's3'],
            'docker': ['docker', 'containerization', 'containers'],
            'kubernetes': ['kubernetes', 'k8s'],
            'git': ['git', 'github', 'version control'],
        }
        
        # Result caching for consistency (simple in-memory cache)
        self._result_cache = {}
        self._cache_max_size = 100
        
        # Comprehensive skill keywords for job description parsing
        self.skill_keywords = {
            'programming': ['python', 'java', 'javascript', 'typescript', 'c++', 'c#', 'ruby', 'go', 'rust', 'php', 'swift', 'kotlin'],
            'web_frontend': ['react', 'angular', 'vue', 'html', 'css', 'sass', 'scss', 'webpack', 'next.js', 'nuxt.js', 'svelte'],
            'web_backend': ['node.js', 'express', 'django', 'flask', 'spring', 'spring boot', 'fastapi', '.net', 'asp.net', 'laravel'],
            'databases': ['sql', 'mysql', 'postgresql', 'mongodb', 'redis', 'elasticsearch', 'cassandra', 'dynamodb', 'oracle'],
            'cloud': ['aws', 'azure', 'gcp', 'google cloud', 'docker', 'kubernetes', 'terraform', 'ansible', 'jenkins'],
            'data_science': ['machine learning', 'deep learning', 'tensorflow', 'pytorch', 'pandas', 'numpy', 'scikit-learn', 'data analysis'],
            'tools': ['git', 'github', 'gitlab', 'jira', 'ci/cd', 'linux', 'agile', 'scrum', 'devops'],
            'mobile': ['android', 'ios', 'react native', 'flutter', 'xamarin', 'mobile development'],
            'testing': ['unit testing', 'integration testing', 'selenium', 'jest', 'pytest', 'testing'],
            'other': ['api', 'rest', 'graphql', 'microservices', 'blockchain', 'security']
        }
        logger.info("‚úÖ Evidence-Based ATS Service initialized with result validation")
    
    def _generate_cache_key(self, resume_text: str, job_description: str) -> str:
        """Generate a cache key based on resume and job description content"""
        import hashlib
        combined_text = f"{resume_text[:500]}|||{job_description[:500]}"
        return hashlib.md5(combined_text.encode()).hexdigest()
    
    def _validate_result_consistency(self, result: ATSResult) -> bool:
        """Validate that ATS result has consistent scoring and data"""
        try:
            # Check that score breakdown components add up correctly
            expected_score = round(
                result.score_breakdown.skill_match_score * 0.40 +
                result.score_breakdown.experience_score * 0.25 +
                result.score_breakdown.role_fit_score * 0.15 +
                result.score_breakdown.education_match_score * 0.10 +
                result.score_breakdown.certifications_score * 0.05 +
                ((result.score_breakdown.tech_stack_match_score + result.score_breakdown.keyword_match_score) / 2) * 0.05,
                2
            )
            
            # Allow small floating point differences
            score_diff = abs(result.ats_score - expected_score)
            if score_diff > 0.1:
                logger.warning(f"‚ö†Ô∏è Score inconsistency detected: expected {expected_score}, got {result.ats_score}")
                return False
            
            # Validate status matches score thresholds
            if result.ats_score >= 80 and result.status != "SHORTLISTED":
                logger.warning(f"‚ö†Ô∏è Status inconsistency: score {result.ats_score}% should be SHORTLISTED but got {result.status}")
                return False
            elif 50 <= result.ats_score < 80 and result.status != "BORDERLINE - NEEDS IMPROVEMENT":
                logger.warning(f"‚ö†Ô∏è Status inconsistency: score {result.ats_score}% should be BORDERLINE but got {result.status}")
                return False
            elif result.ats_score < 50 and result.status != "NOT SHORTLISTED":
                logger.warning(f"‚ö†Ô∏è Status inconsistency: score {result.ats_score}% should be NOT SHORTLISTED but got {result.status}")
                return False
            
            logger.info(f"‚úÖ Result validation passed: {result.ats_score}% - {result.status}")
            return True
            
        except Exception as e:
            logger.error(f"üí• Error validating result consistency: {str(e)}")
            return False
    
    async def _extract_job_profile(self, job_description_text: str) -> Dict:
        """Extract job profile information from job description text"""
        try:
            logger.info("üìã Extracting job profile from job description")
            
            text_lower = job_description_text.lower()
            
            # Extract job title
            job_title = "Software Engineer"  # Default
            title_patterns = ["position:", "title:", "job title:", "role:", "vacancy:"]
            for line in job_description_text.split('\n')[:10]:  # Check first 10 lines
                line_lower = line.strip().lower()
                for pattern in title_patterns:
                    if pattern in line_lower:
                        potential_title = line.strip().replace(pattern.replace(':', ''), '').strip()
                        if len(potential_title) > 5:
                            job_title = potential_title
                            break
                if job_title != "Software Engineer":
                    break
            
            # If no explicit pattern found, use first meaningful line
            if job_title == "Software Engineer":
                for line in job_description_text.split('\n')[:5]:
                    line = line.strip()
                    if len(line) > 10 and not line.lower().startswith(('we are', 'job', 'position', 'company')):
                        job_title = line
                        break
            
            # Extract mandatory skills (from requirements section)
            mandatory_skills = []
            in_requirements = False
            for line in job_description_text.split('\n'):
                line_lower = line.strip().lower()
                if any(keyword in line_lower for keyword in ['requirements:', 'mandatory:', 'must have:', 'essential:']):
                    in_requirements = True
                    continue
                elif any(keyword in line_lower for keyword in ['preferred:', 'nice to have:', 'bonus:', 'desired:']):
                    in_requirements = False
                    continue
                elif line.strip().startswith('---') or len(line.strip()) == 0:
                    continue
                elif in_requirements and line.strip().startswith(('-', '‚Ä¢', '*', '1.', '2.', '3.')):
                    skill_text = line.strip().lstrip('-‚Ä¢*0123456789. ').strip()
                    # Extract skill names from requirement text
                    for skill_category in self.skill_keywords.keys():
                        if any(keyword in skill_text.lower() for keyword in self.skill_keywords[skill_category]):
                            mandatory_skills.extend(self.skill_keywords[skill_category][:2])  # Add first 2 keywords
                    
                    # Direct skill extraction
                    skill_words = ['python', 'javascript', 'react', 'node.js', 'sql', 'aws', 'docker', 'git']
                    for skill in skill_words:
                        if skill in skill_text.lower() and skill not in mandatory_skills:
                            mandatory_skills.append(skill)
            
            # Extract good-to-have skills (from preferred section)
            good_to_have_skills = []
            in_preferred = False
            for line in job_description_text.split('\n'):
                line_lower = line.strip().lower()
                if any(keyword in line_lower for keyword in ['preferred:', 'nice to have:', 'bonus:', 'desired:', 'additional:']):
                    in_preferred = True
                    continue
                elif in_preferred and line.strip().startswith(('-', '‚Ä¢', '*', '1.', '2.', '3.')):
                    skill_text = line.strip().lstrip('-‚Ä¢*0123456789. ').strip()
                    # Extract preferred skills
                    skill_words = ['typescript', 'mongodb', 'microservices', 'ci/cd', 'machine learning']
                    for skill in skill_words:
                        if skill in skill_text.lower() and skill not in good_to_have_skills:
                            good_to_have_skills.append(skill)
            
            # Extract experience requirements
            required_experience = 0
            exp_patterns = [r'(\d+)\s*\+?\s*years?', r'(\d+)\s*to\s*(\d+)\s*years?']
            import re
            for pattern in exp_patterns:
                matches = re.findall(pattern, text_lower)
                if matches:
                    if isinstance(matches[0], tuple):
                        required_experience = int(matches[0][0])  # Take minimum
                    else:
                        required_experience = int(matches[0])
                    break
            
            # Extract education requirements
            education_requirements = []
            if 'bachelor' in text_lower:
                education_requirements.append("Bachelor's Degree")
            if 'master' in text_lower:
                education_requirements.append("Master's Degree")
            if 'computer science' in text_lower or 'cs' in text_lower:
                education_requirements.append("Computer Science Background")
            
            # Extract tools and technologies
            required_tools_technologies = []
            tech_keywords = ['git', 'sql', 'postgresql', 'mysql', 'aws', 'azure', 'docker', 'kubernetes']
            for tech in tech_keywords:
                if tech in text_lower and tech not in required_tools_technologies:
                    required_tools_technologies.append(tech)
            
            # Extract industry domain
            required_industry_domain = ['Technology', 'Software Development']
            if 'fintech' in text_lower or 'finance' in text_lower:
                required_industry_domain.append('Finance')
            if 'healthcare' in text_lower or 'medical' in text_lower:
                required_industry_domain.append('Healthcare')
            
            # Extract relevant keywords
            relevant_keywords = []
            keyword_patterns = ['full stack', 'web development', 'api development', 'microservices', 'cloud', 'devops']
            for keyword in keyword_patterns:
                if keyword in text_lower and keyword not in relevant_keywords:
                    relevant_keywords.append(keyword)
            
            # Extract preferred certifications
            preferred_certifications = []
            if 'aws' in text_lower and 'cert' in text_lower:
                preferred_certifications.append('AWS Certification')
            if 'azure' in text_lower and 'cert' in text_lower:
                preferred_certifications.append('Azure Certification')
            
            job_profile = {
                'job_title': job_title,
                'mandatory_skills': list(set(mandatory_skills)),
                'good_to_have_skills': list(set(good_to_have_skills)),
                'required_experience': required_experience,
                'education_requirements': education_requirements,
                'preferred_certifications': preferred_certifications,
                'required_tools_technologies': list(set(required_tools_technologies)),
                'required_industry_domain': required_industry_domain,
                'relevant_keywords': list(set(relevant_keywords))
            }
            
            logger.info(f"‚úÖ Job profile extracted: {job_profile['job_title']}")
            return job_profile
            
        except Exception as e:
            logger.error(f"‚ùå Error extracting job profile: {str(e)}")
            # Return default profile
            return {
                'job_title': 'Software Engineer',
                'mandatory_skills': ['python', 'javascript', 'sql'],
                'good_to_have_skills': ['docker', 'aws'],
                'required_experience': 2,
                'education_requirements': ["Bachelor's Degree"],
                'preferred_certifications': [],
                'required_tools_technologies': ['git', 'sql'],
                'required_industry_domain': ['Technology'],
                'relevant_keywords': ['software development', 'programming']
            }
    
    async def evaluate_candidate(self, resume_text: str, job_description: str) -> ATSResult:
        """
        Evidence-driven ATS evaluation using USER'S EXACT SYSTEM PROMPT LOGIC
        
        Returns deterministic, real-time results with evidence for every claim.
        """
        try:
            # Check cache for consistent results (optional optimization)
            cache_key = self._generate_cache_key(resume_text, job_description)
            if cache_key in self._result_cache:
                logger.info("üöÄ Using cached ATS result for consistency")
                cached_result = self._result_cache[cache_key]
                if self._validate_result_consistency(cached_result):
                    return cached_result
                else:
                    # Remove invalid cached result
                    del self._result_cache[cache_key]
            
            logger.info("üîç EVIDENCE-BASED ATS EVALUATION - USER'S EXACT SYSTEM")
            
            # 1) Resume Parsing: extract with evidence (no hallucinations)
            resume_data = await self._parse_resume_with_evidence(resume_text)
            logger.info("‚úÖ Resume parsing complete - evidence-based")
            
            # 2) JD Parsing: extract with evidence
            jd_data = await self._parse_jd_with_evidence(job_description)
            logger.info("‚úÖ JD parsing complete - evidence-based")
            
            # 3) Component Scores: calculate with evidence and rationales
            component_scores = await self._calculate_component_scores(resume_data, jd_data)
            logger.info("‚úÖ Component scores calculated with evidence")
            
            # 4) Weighted ATS Score using USER'S EXACT WEIGHTS
            ats_score = round(
                component_scores["skill_match"]["value"] * 0.40 +      # Skills ‚Üí 40%
                component_scores["experience"]["value"] * 0.25 +       # Experience ‚Üí 25%
                component_scores["role_fit"]["value"] * 0.15 +         # Role Fit ‚Üí 15%
                component_scores["education"]["value"] * 0.10 +        # Education ‚Üí 10%
                component_scores["certifications"]["value"] * 0.05 +   # Certifications ‚Üí 5%
                ((component_scores["tools"]["value"] + component_scores["keyword_match"]["value"]) / 2) * 0.05,  # Tools/Keywords ‚Üí 5%
                2
            )
            
            logger.info(f"üéØ FINAL ATS SCORE: {ats_score}% (USER'S EXACT WEIGHTS)")
            
            # 5) Classification using USER'S EXACT CRITERIA
            if ats_score >= 80:
                status = "SHORTLISTED"
            elif 50 <= ats_score < 80:
                status = "BORDERLINE - NEEDS IMPROVEMENT"
            else:
                status = "NOT SHORTLISTED"
            
            # 6) Missing Skills & Improvements with evidence
            matched_skills, missing_skills = self._analyze_skills_with_evidence(resume_data, jd_data)
            improvement_suggestions = self._generate_evidence_based_improvements(missing_skills, ats_score)
            keywords_to_add = self._extract_missing_keywords(resume_data, jd_data)
            
            # 7) Recruiter Summary (3-4 lines as specified)
            recruiter_summary = self._generate_recruiter_summary(
                resume_data, jd_data, ats_score, status, matched_skills
            )
            
            # Build ATSResult with evidence-based data
            result = ATSResult(
                ats_score=ats_score,
                status=status,
                score_breakdown=ATSScoreBreakdown(
                    skill_match_score=component_scores["skill_match"]["value"],
                    experience_score=component_scores["experience"]["value"],
                    role_fit_score=component_scores["role_fit"]["value"],
                    education_match_score=component_scores["education"]["value"],
                    certifications_score=component_scores["certifications"]["value"],
                    tech_stack_match_score=component_scores["tools"]["value"],
                    keyword_match_score=component_scores["keyword_match"]["value"],
                    matched_skills=[skill["skill"] for skill in matched_skills],
                    missing_skills=[skill["skill"] for skill in missing_skills],
                    matched_tools=resume_data.get("tools_and_technologies", [])[:5],
                    missing_tools=[],
                    matched_keywords=resume_data.get("resume_keywords", [])[:10],
                    missing_keywords=keywords_to_add[:10],
                    matched_certifications=resume_data.get("certifications", []),
                    missing_certifications=[]
                ),
                candidate_profile=ATSCandidateProfile(
                    candidate_summary=resume_data.get("candidate_summary", "INSUFFICIENT_DATA"),
                    total_experience=resume_data.get("total_experience_years", 0),
                    relevant_experience=resume_data.get("relevant_experience_years", 0),
                    technical_skills=resume_data.get("skills", []),
                    soft_skills=[],
                    tools_technologies=resume_data.get("tools_and_technologies", []),
                    certifications=resume_data.get("certifications", []),
                    education_details=resume_data.get("education", []),
                    job_titles=resume_data.get("job_titles", []),
                    projects_responsibilities=resume_data.get("projects_responsibilities", []),
                    achievements_awards=resume_data.get("achievements_awards", []),
                    domain_experience=resume_data.get("domain_experience", []),
                    contact_information=resume_data.get("contact_info", {}),
                    resume_keywords=resume_data.get("resume_keywords", []),
                    seniority_level=resume_data.get("seniority_level", "INSUFFICIENT_DATA")
                ),
                job_profile=ATSJobProfile(
                    mandatory_skills=jd_data.get("mandatory_skills", []),
                    good_to_have_skills=jd_data.get("good_to_have_skills", []),
                    required_experience=jd_data.get("required_experience_years", 0),
                    required_tools_technologies=jd_data.get("required_tools_technologies", []),
                    role_responsibilities=jd_data.get("role_responsibilities", []),
                    education_requirements=jd_data.get("education_requirements", []),
                    preferred_certifications=jd_data.get("preferred_certifications", []),
                    required_industry_domain=jd_data.get("industry_domain", []),
                    relevant_keywords=jd_data.get("jd_keywords", [])
                ),
                professional_summary=recruiter_summary,
                improvement_suggestions=[suggestion["suggestion"] for suggestion in improvement_suggestions],
                keywords_to_add=keywords_to_add,
                final_recommendation=self._generate_final_recommendation(ats_score, status)
            )
            
            # Validate result consistency before returning
            if not self._validate_result_consistency(result):
                logger.error("‚ùå Result validation failed - inconsistent scoring detected")
                raise Exception("Result validation failed - inconsistent ATS scoring")
            
            # Cache the validated result for consistency (with size limit)
            if len(self._result_cache) >= self._cache_max_size:
                # Remove oldest entry (simple FIFO)
                oldest_key = next(iter(self._result_cache))
                del self._result_cache[oldest_key]
            
            self._result_cache[cache_key] = result
            logger.info(f"üíæ Result cached for consistency validation")
            
            return result
            
        except Exception as e:
            logger.error(f"‚ùå Error in ATS evaluation: {str(e)}")
            raise

    async def _parse_resume_with_evidence(self, resume_text: str) -> Dict[str, Any]:
        """Parse resume with evidence-based extraction"""
        text_lower = resume_text.lower()
        
        # Extract candidate summary (first meaningful paragraph)
        candidate_summary = ""
        lines = resume_text.split('\n')
        for i, line in enumerate(lines[:10]):  # Check first 10 lines
            line = line.strip()
            if len(line) > 50 and not any(keyword in line.lower() for keyword in ['email', 'phone', 'address', 'linkedin']):
                candidate_summary = line
                break
        
        # Extract experience years with evidence
        exp_patterns = [
            r'(\d+)\+?\s*years?\s*(?:of\s*)?(?:experience|exp)',
            r'experience:?\s*(\d+)\+?\s*years?',
            r'(\d+)\s*years?\s*(?:of\s*)?(?:professional\s*)?(?:experience|exp)'
        ]
        
        total_experience_years = 0
        exp_evidence = []
        
        for pattern in exp_patterns:
            matches = re.finditer(pattern, text_lower)
            for match in matches:
                years = int(match.group(1))
                if years > total_experience_years:
                    total_experience_years = years
                    exp_evidence.append(match.group(0))
        
        # Keep as integer - 0 means no experience found (instead of string)
        if total_experience_years == 0:
            total_experience_years = 0  # Keep as 0 for Pydantic validation
        
        # Extract skills with evidence
        skill_keywords = [
            'python', 'java', 'javascript', 'react', 'angular', 'vue', 'nodejs', 'express',
            'sql', 'mongodb', 'postgresql', 'mysql', 'aws', 'azure', 'docker', 'kubernetes',
            'git', 'html', 'css', 'typescript', 'c++', 'c#', 'php', 'ruby', 'go', 'swift',
            'tensorflow', 'pytorch', 'scikit-learn', 'pandas', 'numpy', 'machine learning',
            'artificial intelligence', 'deep learning', 'data science', 'blockchain'
        ]
        
        found_skills = []
        for skill in skill_keywords:
            if skill in text_lower:
                found_skills.append(skill.title())
        
        # Extract tools and technologies
        tools_keywords = ['git', 'docker', 'kubernetes', 'jenkins', 'aws', 'azure', 'gcp', 'postman', 'jira']
        found_tools = [tool.title() for tool in tools_keywords if tool in text_lower]
        
        # Extract certifications
        cert_patterns = [
            r'certified?\s+[a-zA-Z\s]+(?:associate|professional|expert|specialist)',
            r'[a-zA-Z\s]+\s+certification',
            r'oracle\s+certified',
            r'microsoft\s+certified',
            r'aws\s+certified',
            r'google\s+cloud'
        ]
        
        found_certs = []
        for pattern in cert_patterns:
            matches = re.finditer(pattern, text_lower)
            for match in matches:
                found_certs.append(match.group(0).title())
        
        # Extract job titles
        title_patterns = [
            r'(?:software\s+)?(?:engineer|developer|programmer|architect)',
            r'(?:senior|junior|lead)\s+(?:developer|engineer)',
            r'(?:full\s+stack|frontend|backend)\s+developer',
            r'data\s+(?:scientist|analyst|engineer)',
            r'devops\s+engineer',
            r'product\s+manager',
            r'project\s+manager'
        ]
        
        found_titles = []
        for pattern in title_patterns:
            matches = re.finditer(pattern, text_lower)
            for match in matches:
                found_titles.append(match.group(0).title())
        
        # Determine seniority level based on experience (total_experience_years is always int now)
        if total_experience_years >= 5:
            seniority = "Senior"
        elif total_experience_years >= 2:
            seniority = "Mid"
        elif total_experience_years > 0:
            seniority = "Junior"
        else:
            seniority = "Entry Level"  # 0 years = Entry Level instead of INSUFFICIENT_DATA
        
        return {
            "candidate_summary": candidate_summary if candidate_summary else "INSUFFICIENT_DATA",
            "total_experience_years": total_experience_years,
            "relevant_experience_years": total_experience_years,  # Default to total
            "skills": found_skills[:15],  # Limit to top 15
            "tools_and_technologies": found_tools,
            "certifications": found_certs,
            "education": ["Bachelor's Degree"] if "bachelor" in text_lower or "b.e" in text_lower or "b.tech" in text_lower else ["INSUFFICIENT_DATA"],
            "job_titles": list(set(found_titles))[:5],  # Top 5 unique
            "projects_responsibilities": self._extract_simple_projects(resume_text),
            "achievements_awards": self._extract_simple_achievements(resume_text),
            "domain_experience": self._extract_simple_domain(text_lower),
            "contact_info": self._extract_contact_info(resume_text),
            "resume_keywords": found_skills + found_tools,
            "seniority_level": seniority
        }
    
    async def _parse_jd_with_evidence(self, jd_text: str) -> Dict[str, Any]:
        """Parse job description with evidence-based extraction"""
        text_lower = jd_text.lower()
        
        # Extract required experience
        exp_patterns = [
            r'(\d+)(?:-(\d+))?\+?\s*years?\s*(?:of\s*)?(?:experience|exp)',
            r'minimum\s+(\d+)\s*years?',
            r'at\s+least\s+(\d+)\s*years?'
        ]
        
        required_experience = 0
        for pattern in exp_patterns:
            matches = re.finditer(pattern, text_lower)
            for match in matches:
                years = int(match.group(1))
                if years > required_experience:
                    required_experience = years
        
        # Extract mandatory skills (common technical skills)
        mandatory_skill_patterns = [
            'python', 'java', 'javascript', 'react', 'angular', 'node.js',
            'sql', 'mongodb', 'aws', 'docker', 'git', 'html', 'css'
        ]
        
        mandatory_skills = [skill.title() for skill in mandatory_skill_patterns if skill in text_lower]
        
        # Extract good to have skills
        good_to_have_patterns = [
            'tensorflow', 'pytorch', 'kubernetes', 'azure', 'gcp',
            'machine learning', 'artificial intelligence', 'blockchain'
        ]
        
        good_to_have_skills = [skill.title() for skill in good_to_have_patterns if skill in text_lower]
        
        # Fix data types for Pydantic validation
        education_req = []
        if "bachelor" in text_lower or "degree" in text_lower:
            education_req = ["Bachelor's Degree"]
            
        industry_domain = []
        if "software" in text_lower or "tech" in text_lower:
            industry_domain = ["Technology"]
        
        return {
            "mandatory_skills": mandatory_skills[:10],  # Top 10
            "good_to_have_skills": good_to_have_skills[:5],  # Top 5
            "required_experience_years": required_experience if required_experience > 0 else 0,  # Default to 0 instead of string
            "required_tools_technologies": ["Git", "AWS", "Docker"] if any(tool in text_lower for tool in ['git', 'aws', 'docker']) else [],
            "role_responsibilities": self._extract_simple_responsibilities(jd_text),
            "education_requirements": education_req,  # List instead of string
            "preferred_certifications": ["AWS Certified"] if "aws" in text_lower else [],
            "industry_domain": industry_domain,  # List instead of string
            "jd_keywords": mandatory_skills + good_to_have_skills
        }
    
    async def _calculate_component_scores(self, resume_data: Dict, jd_data: Dict) -> Dict[str, Dict]:
        """Calculate component scores with evidence and explanations"""
        
        # Skill Match Score (0-100)
        resume_skills = set([skill.lower() for skill in resume_data.get("skills", [])])
        required_skills = set([skill.lower() for skill in jd_data.get("mandatory_skills", [])])
        
        if required_skills:
            skill_matches = len(resume_skills.intersection(required_skills))
            skill_match_score = min(100, (skill_matches / len(required_skills)) * 100)
        else:
            skill_match_score = 0
        
        # Experience Score (0-100)
        resume_exp = resume_data.get("total_experience_years", 0)
        required_exp = jd_data.get("required_experience_years", 0)
        
        if isinstance(resume_exp, int) and isinstance(required_exp, int) and required_exp > 0:
            exp_ratio = resume_exp / required_exp
            experience_score = min(100, exp_ratio * 100)
        else:
            experience_score = 50  # Default if insufficient data
        
        # Role Fit Score (based on job titles)
        resume_titles = resume_data.get("job_titles", [])
        role_keywords = ["developer", "engineer", "programmer", "architect"]
        role_matches = sum(1 for title in resume_titles for keyword in role_keywords if keyword.lower() in title.lower())
        role_fit_score = min(100, role_matches * 25)  # 25 points per matching title
        
        # Education Score (0 or 100)
        resume_edu = resume_data.get("education", [])
        jd_edu = jd_data.get("education_requirements", "")
        education_score = 100 if resume_edu and resume_edu[0] != "INSUFFICIENT_DATA" else 0
        
        # Certifications Score
        resume_certs = resume_data.get("certifications", [])
        certifications_score = min(100, len(resume_certs) * 20)  # 20 points per cert
        
        # Tools Score
        resume_tools = set([tool.lower() for tool in resume_data.get("tools_and_technologies", [])])
        required_tools = set([tool.lower() for tool in jd_data.get("required_tools_technologies", [])])
        
        if required_tools:
            tool_matches = len(resume_tools.intersection(required_tools))
            tools_score = min(100, (tool_matches / len(required_tools)) * 100)
        else:
            tools_score = 50  # Default if no specific tools required
        
        # Keyword Match Score
        resume_keywords = set([kw.lower() for kw in resume_data.get("resume_keywords", [])])
        jd_keywords = set([kw.lower() for kw in jd_data.get("jd_keywords", [])])
        
        if jd_keywords:
            keyword_matches = len(resume_keywords.intersection(jd_keywords))
            keyword_score = min(100, (keyword_matches / len(jd_keywords)) * 100)
        else:
            keyword_score = 50
        
        return {
            "skill_match": {
                "value": round(skill_match_score, 1),
                "explanation": f"Matched {len(resume_skills.intersection(required_skills))}/{len(required_skills)} required skills",
                "evidence": list(resume_skills.intersection(required_skills))
            },
            "experience": {
                "value": round(experience_score, 1),
                "explanation": f"Has {resume_exp} years vs {required_exp} years required",
                "evidence": []
            },
            "role_fit": {
                "value": round(role_fit_score, 1),
                "explanation": f"Found {role_matches} relevant job titles",
                "evidence": resume_titles
            },
            "education": {
                "value": round(education_score, 1),
                "explanation": "Education requirements met" if education_score > 0 else "Education requirements not clear",
                "evidence": resume_edu
            },
            "certifications": {
                "value": round(certifications_score, 1),
                "explanation": f"Has {len(resume_certs)} certifications",
                "evidence": resume_certs
            },
            "tools": {
                "value": round(tools_score, 1),
                "explanation": f"Matched tools and technologies",
                "evidence": list(resume_tools.intersection(required_tools))
            },
            "keyword_match": {
                "value": round(keyword_score, 1),
                "explanation": f"Matched keywords in resume",
                "evidence": list(resume_keywords.intersection(jd_keywords))
            }
        }
    
    def _analyze_skills_with_evidence(self, resume_data: Dict, jd_data: Dict) -> Tuple[List[Dict], List[Dict]]:
        """Analyze matched and missing skills with evidence"""
        resume_skills = set([skill.lower() for skill in resume_data.get("skills", [])])
        required_skills = set([skill.lower() for skill in jd_data.get("mandatory_skills", [])])
        
        matched = [{"skill": skill, "evidence": [skill]} for skill in resume_skills.intersection(required_skills)]
        missing = [{"skill": skill, "priority": 1} for skill in required_skills - resume_skills]
        
        return matched, missing[:10]  # Limit to top 10 missing
    
    def _generate_evidence_based_improvements(self, missing_skills: List[Dict], ats_score: float) -> List[Dict]:
        """Generate improvement suggestions based on missing skills"""
        suggestions = []
        
        for skill in missing_skills[:5]:  # Top 5 missing skills
            skill_name = skill["skill"]
            if skill_name.lower() == "python":
                suggestions.append({"suggestion": "Learn Python programming - Take 'Python for Everybody' on Coursera"})
            elif skill_name.lower() == "react":
                suggestions.append({"suggestion": "Master React.js - Build a portfolio project with React"})
            elif skill_name.lower() == "aws":
                suggestions.append({"suggestion": "Get AWS certified - Start with AWS Cloud Practitioner certification"})
            else:
                suggestions.append({"suggestion": f"Learn {skill_name} - Practice with online tutorials and projects"})
        
        if ats_score < 60:
            suggestions.append({"suggestion": "Consider additional technical training to meet job requirements"})
        
        return suggestions
    
    def _extract_missing_keywords(self, resume_data: Dict, jd_data: Dict) -> List[str]:
        """Extract keywords that should be added to resume"""
        resume_keywords = set([kw.lower() for kw in resume_data.get("resume_keywords", [])])
        jd_keywords = set([kw.lower() for kw in jd_data.get("jd_keywords", [])])
        
        missing = list(jd_keywords - resume_keywords)
        return [kw.title() for kw in missing[:10]]
    
    def _generate_recruiter_summary(self, resume_data: Dict, jd_data: Dict, ats_score: float, status: str, matched_skills: List[Dict]) -> str:
        """Generate 3-4 line recruiter summary as specified"""
        exp_years = resume_data.get("total_experience_years", "N/A")
        skill_count = len(matched_skills)
        total_required = len(jd_data.get("mandatory_skills", []))
        
        line1 = f"Candidate shows {ats_score}% overall fit with {exp_years} years of experience."
        line2 = f"Strong match in {skill_count}/{total_required} required skills. Status: {status}."
        line3 = f"Profile: {resume_data.get('seniority_level', 'Unknown')} level professional with {resume_data.get('domain_experience', ['Technology'])[0]} background."
        
        if status == "SHORTLISTED":
            line4 = "Recommended for interview - strong technical alignment and experience match."
        elif status == "BORDERLINE - NEEDS IMPROVEMENT":
            line4 = "Borderline candidate - some skill gaps but potential for growth with training."
        else:
            line4 = "Not recommended - significant skill and experience gaps present."
        
        return f"{line1} {line2} {line3} {line4}"
    
    def _generate_final_recommendation(self, ats_score: float, status: str) -> str:
        """Generate final recommendation"""
        if status == "SHORTLISTED":
            return f"RECOMMEND FOR INTERVIEW: Strong candidate with {ats_score}% ATS match. Proceed to technical screening."
        elif status == "BORDERLINE - NEEDS IMPROVEMENT":
            return f"CONDITIONAL CONSIDERATION: {ats_score}% match with some gaps. Consider for junior roles or with additional training."
        else:
            return f"NOT RECOMMENDED: {ats_score}% match with significant gaps. Does not meet current role requirements."
    
    # Helper methods for simple extraction
    def _extract_simple_projects(self, text: str) -> List[str]:
        """Simple project extraction"""
        projects = []
        if "project" in text.lower():
            lines = text.split('\n')
            for line in lines:
                if "project" in line.lower() and len(line) > 20:
                    projects.append(line.strip()[:100])
        return projects[:3]
    
    def _extract_simple_achievements(self, text: str) -> List[str]:
        """Simple achievement extraction"""
        achievements = []
        achievement_keywords = ["award", "achievement", "recognition", "honor", "scholarship"]
        lines = text.split('\n')
        for line in lines:
            if any(keyword in line.lower() for keyword in achievement_keywords):
                achievements.append(line.strip()[:100])
        return achievements[:3]
    
    def _extract_simple_domain(self, text_lower: str) -> List[str]:
        """Simple domain extraction"""
        domains = []
        if "finance" in text_lower or "banking" in text_lower:
            domains.append("Finance")
        elif "healthcare" in text_lower or "medical" in text_lower:
            domains.append("Healthcare")
        elif "education" in text_lower:
            domains.append("Education")
        else:
            domains.append("Technology")
        return domains
    
    def _extract_simple_responsibilities(self, text: str) -> List[str]:
        """Simple responsibility extraction"""
        responsibilities = []
        lines = text.split('\n')
        for line in lines:
            if any(word in line.lower() for word in ["develop", "design", "implement", "manage", "lead"]):
                if len(line.strip()) > 20:
                    responsibilities.append(line.strip()[:100])
        return responsibilities[:5]
    
    def _extract_contact_info(self, text: str) -> Dict[str, str]:
        """Extract contact information"""
        contact = {}
        
        # Email
        email_pattern = r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b'
        email_match = re.search(email_pattern, text)
        if email_match:
            contact["email"] = email_match.group(0)
        
        # Phone
        phone_pattern = r'[\+]?[1-9]?[0-9]{7,15}'
        phone_match = re.search(phone_pattern, text)
        if phone_match:
            contact["phone"] = phone_match.group(0)
        
        return contact if contact else {"email": "INSUFFICIENT_DATA", "phone": "INSUFFICIENT_DATA"}